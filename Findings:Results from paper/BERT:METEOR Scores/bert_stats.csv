,mean,median,std,min,max,range
gpt-4o,0.8010915937631027,0.8043918907642365,0.07836566196172824,0.5830520391464233,1.0,0.41694796085357666
Tiny Llama Unsloth,0.38223792353402014,0.3749161660671234,0.07692910974478923,0.2320438623428344,0.9177704453468324,0.685726583003998
aya-23-8B,0.6669174476810124,0.676139235496521,0.1126385476144735,0.3356850743293762,0.933026909828186,0.5973418354988098
Llama & Assistant,0.7907732025436733,0.8027167916297913,0.11111061328367937,0.2789580225944519,1.0,0.7210419774055481
Llama 3 Unsloth,0.8522258369818978,0.8612666130065918,0.10259918640278123,0.2582998275756836,1.0000001192092896,0.741700291633606
Meta-Llama-3-8B-Instruct,0.5634789087850115,0.6046078503131866,0.18116250578888662,0.2468401044607162,0.8897985816001892,0.642958477139473
Llama 2 Unsloth,0.7858239300872969,0.7980637550354004,0.12397275095834906,0.3257438838481903,1.0,0.6742561161518097
mistral unsloth,0.8639606024907983,0.8716927170753479,0.08626917277491636,0.5163522362709045,1.0000001192092896,0.483647882938385
mistral-7B-instruct-v0.3,0.7281254782624866,0.726071834564209,0.08345307858974649,0.4821650385856628,0.94797021150589,0.4658051729202272
Llama 3 ORPO,0.6169989955166112,0.6649391353130341,0.1796494163732517,0.2756747305393219,0.9660544395446776,0.6903797090053557
